{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78914450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib\n",
    "import csv\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fb20cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input('what is the category of products you want scrapping? : ')\n",
    "pages_number = 1  # Reduced for testing\n",
    "Company_details = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33d41d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tech_Behemoths():\n",
    "    try:\n",
    "        # Set up Chrome options to avoid detection\n",
    "        chrome_options = Options()\n",
    "        \n",
    "        # Anti-detection settings\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "        chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "        \n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        browser = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        \n",
    "        # Execute CDP commands to prevent detection\n",
    "        browser.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "            \"source\": \"\"\"\n",
    "                Object.defineProperty(navigator, 'webdriver', {\n",
    "                    get: () => undefined\n",
    "                })\n",
    "            \"\"\"\n",
    "        })\n",
    "\n",
    "        for n in range(1, pages_number + 1):  # Fixed: use n instead of pages_number\n",
    "            url = f'https://techbehemoths.com/companies?page={n}'  # Fixed: use n\n",
    "            print(f\"Scraping page {n}: {url}\")\n",
    "            \n",
    "            browser.get(url)\n",
    "            browser.maximize_window()\n",
    "            \n",
    "            # Random delay to appear more human-like\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Check if we got blocked\n",
    "            page_title = browser.title\n",
    "            if \"error\" in browser.current_url.lower() or \"block\" in page_title.lower():\n",
    "                print(\"Website blocked the request. Stopping...\")\n",
    "                break\n",
    "\n",
    "            \n",
    "            Company_list = browser.find_elements(By.XPATH , \"//div[@class='co-list__itm']\")\n",
    "            \n",
    "            if not Company_list:\n",
    "                print(\"No Companys found on this page. The site might have changed structure.\")\n",
    "                # Try to get page content for debugging\n",
    "                print(\"Page title:\", browser.title)\n",
    "                continue\n",
    "\n",
    "            print(f\"Found {len(Company_list)} Companys on page {n}\")\n",
    "\n",
    "            for Company in Company_list:\n",
    "                try:\n",
    "                    html_code = Company.get_attribute('outerHTML')\n",
    "                    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "                    \n",
    "                    # More flexible selectors with multiple fallbacks\n",
    "                    \n",
    "                    try:\n",
    "                        Com_Name = soup.find('p',{'class':'co-box__name'} ).text.strip()\n",
    "                    except:\n",
    "                        Com_Name = 'No name'\n",
    "                    try:\n",
    "                        Com_Description = soup.find('p',{'class':'co-box__descr'}).text()\n",
    "                    except:\n",
    "                        Com_Description = 'Not Found'\n",
    "                    try:\n",
    "                        Com_Size = soup.find('span', {'class','value'}).text()\n",
    "                    except:\n",
    "                        Com_Size = 'Not Found'\n",
    "                    try:\n",
    "                        Hourly_Rate = soup.find('span',{'class':'co-box__tltip-txt flex-centered absolute ext-highlight'}).text().strip()\n",
    "                    except:\n",
    "                        Hourly_Rate = 'Not Found'\n",
    "                    try:\n",
    "                        Services = soup.find('div', {'class':'txt'}).text().strip()\n",
    "                    except:\n",
    "                        Services = 'Not Found'\n",
    "                    try:\n",
    "                        Company_URl = soup.find('a').get('href')\n",
    "                    except:\n",
    "                        Company_URl = 'Not Found'\n",
    "\n",
    "                    Company_details.append({\n",
    "                        'Com_Name': Com_Name,\n",
    "                        'Page': n,\n",
    "                        'Com_Size':Com_Size,\n",
    "                        'Hourly_Rate':Hourly_Rate,\n",
    "                        'Services':Services,\n",
    "                        'Com_Description':Com_Description,\n",
    "                        'Company_URl':'https://techbehemoths.com' + Company_URl\n",
    "                    })\n",
    "                    \n",
    "                except Exception as Company_error:\n",
    "                    print(f\"Error processing a Company: {Company_error}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Total Companys collected so far: {len(Company_details)}\")\n",
    "            \n",
    "            # Add delay between pages\n",
    "            if n < pages_number:\n",
    "                time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'something went wrong with Tech_Behemoths ==> {e}')\n",
    "    finally:\n",
    "        if 'browser' in locals():\n",
    "            browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b8711dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Printing_file():\n",
    "    try:\n",
    "        if not Company_details:\n",
    "            print(\"No data to save!\")\n",
    "            return\n",
    "            \n",
    "        path = './Tech_Behemoths_Companies.csv'\n",
    "        columns = Company_details[0].keys()\n",
    "        with open(path, 'w', newline='', encoding='UTF-8') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, columns)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(Company_details)\n",
    "        print(f'File Printed Successfully with {len(Company_details)} records')\n",
    "    except Exception as e:\n",
    "        print(f'something went wrong with Printing_file ==> {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f324ef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1: https://techbehemoths.com/companies?page=1\n",
      "Found 18 Companys on page 1\n",
      "Total Companys collected so far: 18\n"
     ]
    }
   ],
   "source": [
    "# Run the functions\n",
    "Tech_Behemoths()\n",
    "#Printing_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd786579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Com_Name</th>\n",
       "      <th>Page</th>\n",
       "      <th>Com_Size</th>\n",
       "      <th>Hourly_Rate</th>\n",
       "      <th>Services</th>\n",
       "      <th>Com_Description</th>\n",
       "      <th>Company_URl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SEO Vultures\\n        Verified Company</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://techbehemoths.com/company/seo-vultures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Crocoapps\\n        Verified Company</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://techbehemoths.com/company/crocoapps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Penguin Publishers\\n        Verified Company</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://techbehemoths.com/company/penguin-publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kuchoriya TechSoft\\n        Verified Company</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://techbehemoths.com/company/kuchoriya-te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Innoventix Solutions\\n        Verified Company</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://techbehemoths.com/company/innoventix-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Com_Name  Page   Com_Size  \\\n",
       "13          SEO Vultures\\n        Verified Company     1  Not Found   \n",
       "14             Crocoapps\\n        Verified Company     1  Not Found   \n",
       "15    Penguin Publishers\\n        Verified Company     1  Not Found   \n",
       "16    Kuchoriya TechSoft\\n        Verified Company     1  Not Found   \n",
       "17  Innoventix Solutions\\n        Verified Company     1  Not Found   \n",
       "\n",
       "   Hourly_Rate   Services Com_Description  \\\n",
       "13   Not Found  Not Found       Not Found   \n",
       "14   Not Found  Not Found       Not Found   \n",
       "15   Not Found  Not Found       Not Found   \n",
       "16   Not Found  Not Found       Not Found   \n",
       "17   Not Found  Not Found       Not Found   \n",
       "\n",
       "                                          Company_URl  \n",
       "13     https://techbehemoths.com/company/seo-vultures  \n",
       "14        https://techbehemoths.com/company/crocoapps  \n",
       "15  https://techbehemoths.com/company/penguin-publ...  \n",
       "16  https://techbehemoths.com/company/kuchoriya-te...  \n",
       "17  https://techbehemoths.com/company/innoventix-s...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(Company_details)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57939554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
